{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c9e593e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "from typing import List\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb96ce98",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_data_path = './EEG/number'\n",
    "processed_data_path = './EEG/processed_data'\n",
    "split_data_path = './EEG/split_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62c74d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = os.listdir(participant_data_path)\n",
    "participants=[]\n",
    "for p in ps:\n",
    "    p= p[:3]\n",
    "    if p not in participants:\n",
    "        participants.append(p)\n",
    "        \n",
    "participants= sorted(participants)\n",
    "# participants, len(participants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28f3009e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "load_name=f\"userfold_data_scaled_p_dictionary-number\"\n",
    "data_dir = \"./EEG/split_data/standard_scaled\"\n",
    "try:\n",
    "    raw_user_fold= pickle.load(open(os.path.join(data_dir, f\"{load_name}.pkl\"), \"rb\"))\n",
    "except:\n",
    "    print(f\"pickle file does not exist. Use EEG-Preprocess.ipynb and EEG-Split.ipynb to save data setting.\")\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "082a80ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109 13\n",
      "\n",
      "c0_acc 0.9819819819819819 , c1_acc 0.26 , b_acc 0.620990990990991\n",
      "107 12\n",
      "\n",
      "c0_acc 0.9304347826086956 , c1_acc 0.22641509433962265 , b_acc 0.5784249384741591\n",
      "110 9\n",
      "\n",
      "c0_acc 0.8943089430894309 , c1_acc 0.16981132075471697 , b_acc 0.5320601319220739\n",
      "124 11\n",
      "\n",
      "c0_acc 0.9465648854961832 , c1_acc 0.19642857142857142 , b_acc 0.5714967284623773\n",
      "111 9\n",
      "\n",
      "c0_acc 0.9487179487179487 , c1_acc 0.1836734693877551 , b_acc 0.5661957090528519\n",
      "118 5\n",
      "\n",
      "c0_acc 0.944 , c1_acc 0.1 , b_acc 0.522\n",
      "111 16\n",
      "\n",
      "c0_acc 0.888 , c1_acc 0.2857142857142857 , b_acc 0.5868571428571429\n",
      "120 10\n",
      "\n",
      "c0_acc 0.9523809523809523 , c1_acc 0.1694915254237288 , b_acc 0.5609362389023406\n",
      "124 21\n",
      "\n",
      "c0_acc 0.9323308270676691 , c1_acc 0.38181818181818183 , b_acc 0.6570745044429255\n",
      "119 23\n",
      "\n",
      "c0_acc 0.9224806201550387 , c1_acc 0.3898305084745763 , b_acc 0.6561555643148075\n",
      "109 8\n",
      "\n",
      "c0_acc 0.9159663865546218 , c1_acc 0.16666666666666666 , b_acc 0.5413165266106442\n",
      "119 28\n",
      "\n",
      "c0_acc 0.9754098360655737 , c1_acc 0.5185185185185185 , b_acc 0.7469641772920461\n",
      "115 18\n",
      "\n",
      "c0_acc 0.9349593495934959 , c1_acc 0.32142857142857145 , b_acc 0.6281939605110337\n",
      "118 4\n",
      "\n",
      "c0_acc 0.944 , c1_acc 0.07142857142857142 , b_acc 0.5077142857142857\n",
      "117 4\n",
      "\n",
      "c0_acc 0.9212598425196851 , c1_acc 0.07142857142857142 , b_acc 0.49634420697412823\n",
      "123 6\n",
      "\n",
      "c0_acc 0.9609375 , c1_acc 0.10909090909090909 , b_acc 0.5350142045454546\n",
      "112 8\n",
      "\n",
      "c0_acc 0.9655172413793104 , c1_acc 0.16 , b_acc 0.5627586206896552\n",
      "122 10\n",
      "\n",
      "c0_acc 0.9682539682539683 , c1_acc 0.1724137931034483 , b_acc 0.5703338806787083\n",
      "121 19\n",
      "\n",
      "c0_acc 0.968 , c1_acc 0.34545454545454546 , b_acc 0.6567272727272727\n",
      "107 26\n",
      "\n",
      "c0_acc 0.963963963963964 , c1_acc 0.52 , b_acc 0.741981981981982\n",
      "109 9\n",
      "\n",
      "c0_acc 0.9478260869565217 , c1_acc 0.16981132075471697 , b_acc 0.5588187038556194\n",
      "112 7\n",
      "\n",
      "c0_acc 0.9105691056910569 , c1_acc 0.1320754716981132 , b_acc 0.5213222886945851\n",
      "123 11\n",
      "\n",
      "c0_acc 0.9389312977099237 , c1_acc 0.19642857142857142 , b_acc 0.5676799345692476\n",
      "115 8\n",
      "\n",
      "c0_acc 0.9829059829059829 , c1_acc 0.16326530612244897 , b_acc 0.573085644514216\n",
      "120 3\n",
      "\n",
      "c0_acc 0.96 , c1_acc 0.06 , b_acc 0.51\n",
      "112 20\n",
      "\n",
      "c0_acc 0.896 , c1_acc 0.35714285714285715 , b_acc 0.6265714285714286\n",
      "118 8\n",
      "\n",
      "c0_acc 0.9365079365079365 , c1_acc 0.13559322033898305 , b_acc 0.5360505784234598\n",
      "129 16\n",
      "\n",
      "c0_acc 0.9699248120300752 , c1_acc 0.2909090909090909 , b_acc 0.630416951469583\n",
      "121 16\n",
      "\n",
      "c0_acc 0.937984496124031 , c1_acc 0.2711864406779661 , b_acc 0.6045854684009986\n",
      "112 8\n",
      "\n",
      "c0_acc 0.9411764705882353 , c1_acc 0.16666666666666666 , b_acc 0.553921568627451\n",
      "118 26\n",
      "\n",
      "c0_acc 0.9672131147540983 , c1_acc 0.48148148148148145 , b_acc 0.7243472981177899\n",
      "118 12\n",
      "\n",
      "c0_acc 0.959349593495935 , c1_acc 0.21428571428571427 , b_acc 0.5868176538908246\n",
      "121 5\n",
      "\n",
      "c0_acc 0.968 , c1_acc 0.08928571428571429 , b_acc 0.5286428571428571\n",
      "124 8\n",
      "\n",
      "c0_acc 0.9763779527559056 , c1_acc 0.14285714285714285 , b_acc 0.5596175478065242\n",
      "122 10\n",
      "\n",
      "c0_acc 0.953125 , c1_acc 0.18181818181818182 , b_acc 0.5674715909090909\n",
      "104 17\n",
      "\n",
      "c0_acc 0.896551724137931 , c1_acc 0.34 , b_acc 0.6182758620689656\n",
      "120 9\n",
      "\n",
      "c0_acc 0.9523809523809523 , c1_acc 0.15517241379310345 , b_acc 0.5537766830870279\n",
      "119 25\n",
      "\n",
      "c0_acc 0.952 , c1_acc 0.45454545454545453 , b_acc 0.7032727272727273\n",
      "107 21\n",
      "\n",
      "c0_acc 0.963963963963964 , c1_acc 0.42 , b_acc 0.691981981981982\n",
      "107 10\n",
      "\n",
      "c0_acc 0.9304347826086956 , c1_acc 0.18867924528301888 , b_acc 0.5595570139458572\n",
      "115 7\n",
      "\n",
      "c0_acc 0.9349593495934959 , c1_acc 0.1320754716981132 , b_acc 0.5335174106458046\n",
      "123 11\n",
      "\n",
      "c0_acc 0.9389312977099237 , c1_acc 0.19642857142857142 , b_acc 0.5676799345692476\n",
      "106 10\n",
      "\n",
      "c0_acc 0.905982905982906 , c1_acc 0.20408163265306123 , b_acc 0.5550322693179837\n",
      "120 7\n",
      "\n",
      "c0_acc 0.96 , c1_acc 0.14 , b_acc 0.55\n",
      "107 16\n",
      "\n",
      "c0_acc 0.856 , c1_acc 0.2857142857142857 , b_acc 0.5708571428571428\n",
      "119 6\n",
      "\n",
      "c0_acc 0.9444444444444444 , c1_acc 0.1016949152542373 , b_acc 0.5230696798493408\n",
      "124 15\n",
      "\n",
      "c0_acc 0.9323308270676691 , c1_acc 0.2727272727272727 , b_acc 0.6025290498974709\n",
      "121 13\n",
      "\n",
      "c0_acc 0.937984496124031 , c1_acc 0.22033898305084745 , b_acc 0.5791617395874392\n",
      "117 7\n",
      "\n",
      "c0_acc 0.9831932773109243 , c1_acc 0.14583333333333334 , b_acc 0.5645133053221288\n",
      "120 21\n",
      "\n",
      "c0_acc 0.9836065573770492 , c1_acc 0.3888888888888889 , b_acc 0.686247723132969\n",
      "118 15\n",
      "\n",
      "c0_acc 0.959349593495935 , c1_acc 0.26785714285714285 , b_acc 0.6136033681765389\n",
      "116 10\n",
      "\n",
      "c0_acc 0.928 , c1_acc 0.17857142857142858 , b_acc 0.5532857142857143\n",
      "121 12\n",
      "\n",
      "c0_acc 0.952755905511811 , c1_acc 0.21428571428571427 , b_acc 0.5835208098987626\n",
      "126 3\n",
      "\n",
      "c0_acc 0.984375 , c1_acc 0.05454545454545454 , b_acc 0.5194602272727272\n",
      "106 14\n",
      "\n",
      "c0_acc 0.9137931034482759 , c1_acc 0.28 , b_acc 0.596896551724138\n",
      "119 6\n",
      "\n",
      "c0_acc 0.9444444444444444 , c1_acc 0.10344827586206896 , b_acc 0.5239463601532567\n",
      "118 19\n",
      "\n",
      "c0_acc 0.944 , c1_acc 0.34545454545454546 , b_acc 0.6447272727272727\n",
      "108 17\n",
      "\n",
      "c0_acc 0.972972972972973 , c1_acc 0.34 , b_acc 0.6564864864864866\n",
      "105 9\n",
      "\n",
      "c0_acc 0.9130434782608695 , c1_acc 0.16981132075471697 , b_acc 0.5414273995077933\n",
      "117 6\n",
      "\n",
      "c0_acc 0.9512195121951219 , c1_acc 0.11320754716981132 , b_acc 0.5322135296824666\n",
      "122 12\n",
      "\n",
      "c0_acc 0.9312977099236641 , c1_acc 0.21428571428571427 , b_acc 0.5727917121046892\n",
      "107 13\n",
      "\n",
      "c0_acc 0.9145299145299145 , c1_acc 0.2653061224489796 , b_acc 0.589918018489447\n",
      "114 5\n",
      "\n",
      "c0_acc 0.912 , c1_acc 0.1 , b_acc 0.506\n",
      "112 15\n",
      "\n",
      "c0_acc 0.896 , c1_acc 0.26785714285714285 , b_acc 0.5819285714285715\n",
      "115 6\n",
      "\n",
      "c0_acc 0.9126984126984127 , c1_acc 0.1016949152542373 , b_acc 0.507196663976325\n",
      "128 17\n",
      "\n",
      "c0_acc 0.9624060150375939 , c1_acc 0.3090909090909091 , b_acc 0.6357484620642515\n",
      "125 14\n",
      "\n",
      "c0_acc 0.9689922480620154 , c1_acc 0.23728813559322035 , b_acc 0.6031401918276179\n",
      "115 6\n",
      "\n",
      "c0_acc 0.9663865546218487 , c1_acc 0.125 , b_acc 0.5456932773109244\n",
      "116 23\n",
      "\n",
      "c0_acc 0.9508196721311475 , c1_acc 0.42592592592592593 , b_acc 0.6883727990285367\n",
      "116 21\n",
      "\n",
      "c0_acc 0.943089430894309 , c1_acc 0.375 , b_acc 0.6590447154471545\n",
      "118 9\n",
      "\n",
      "c0_acc 0.944 , c1_acc 0.16071428571428573 , b_acc 0.5523571428571429\n",
      "123 12\n",
      "\n",
      "c0_acc 0.968503937007874 , c1_acc 0.21428571428571427 , b_acc 0.5913948256467941\n",
      "127 2\n",
      "\n",
      "c0_acc 0.9921875 , c1_acc 0.03636363636363636 , b_acc 0.5142755681818182\n",
      "108 14\n",
      "\n",
      "c0_acc 0.9310344827586207 , c1_acc 0.28 , b_acc 0.6055172413793104\n",
      "118 11\n",
      "\n",
      "c0_acc 0.9365079365079365 , c1_acc 0.1896551724137931 , b_acc 0.5630815544608648\n",
      "119 25\n",
      "\n",
      "c0_acc 0.952 , c1_acc 0.45454545454545453 , b_acc 0.7032727272727273\n",
      "108 18\n",
      "\n",
      "c0_acc 0.972972972972973 , c1_acc 0.36 , b_acc 0.6664864864864866\n",
      "110 10\n",
      "\n",
      "c0_acc 0.9565217391304348 , c1_acc 0.18867924528301888 , b_acc 0.5726004922067268\n",
      "113 8\n",
      "\n",
      "c0_acc 0.9186991869918699 , c1_acc 0.1509433962264151 , b_acc 0.5348212916091425\n",
      "126 10\n",
      "\n",
      "c0_acc 0.9618320610687023 , c1_acc 0.17857142857142858 , b_acc 0.5702017448200655\n",
      "106 11\n",
      "\n",
      "c0_acc 0.905982905982906 , c1_acc 0.22448979591836735 , b_acc 0.5652363509506366\n",
      "119 4\n",
      "\n",
      "c0_acc 0.952 , c1_acc 0.08 , b_acc 0.516\n",
      "111 15\n",
      "\n",
      "c0_acc 0.888 , c1_acc 0.26785714285714285 , b_acc 0.5779285714285715\n",
      "121 5\n",
      "\n",
      "c0_acc 0.9603174603174603 , c1_acc 0.0847457627118644 , b_acc 0.5225316115146623\n",
      "126 14\n",
      "\n",
      "c0_acc 0.9473684210526315 , c1_acc 0.2545454545454545 , b_acc 0.600956937799043\n",
      "128 5\n",
      "\n",
      "c0_acc 0.9922480620155039 , c1_acc 0.0847457627118644 , b_acc 0.5384969123636841\n",
      "109 10\n",
      "\n",
      "c0_acc 0.9159663865546218 , c1_acc 0.20833333333333334 , b_acc 0.5621498599439776\n",
      "117 25\n",
      "\n",
      "c0_acc 0.9590163934426229 , c1_acc 0.46296296296296297 , b_acc 0.7109896782027929\n",
      "113 9\n",
      "\n",
      "c0_acc 0.9186991869918699 , c1_acc 0.16071428571428573 , b_acc 0.5397067363530779\n",
      "120 8\n",
      "\n",
      "c0_acc 0.96 , c1_acc 0.14285714285714285 , b_acc 0.5514285714285714\n",
      "119 5\n",
      "\n",
      "c0_acc 0.937007874015748 , c1_acc 0.08928571428571429 , b_acc 0.5131467941507312\n",
      "121 7\n",
      "\n",
      "c0_acc 0.9453125 , c1_acc 0.12727272727272726 , b_acc 0.5362926136363636\n",
      "112 15\n",
      "\n",
      "c0_acc 0.9655172413793104 , c1_acc 0.3 , b_acc 0.6327586206896552\n",
      "119 6\n",
      "\n",
      "c0_acc 0.9444444444444444 , c1_acc 0.10344827586206896 , b_acc 0.5239463601532567\n",
      "122 25\n",
      "\n",
      "c0_acc 0.976 , c1_acc 0.45454545454545453 , b_acc 0.7152727272727273\n",
      "User S01 f1: 0.7507703417804593 acc: 0.782608695652174\n",
      " c0: 0.9819819819819819 c1: 0.26 bacc: 0.620990990990991\n",
      "User S02 f1: 0.6547096450520508 acc: 0.7142857142857143\n",
      " c0: 0.9304347826086956 c1: 0.22641509433962265 bacc: 0.5784249384741591\n",
      "User S03 f1: 0.6299370958849181 acc: 0.6875\n",
      " c0: 0.8943089430894309 c1: 0.16981132075471697 bacc: 0.5320601319220739\n",
      "User S04 f1: 0.6669793739937375 acc: 0.7272727272727273\n",
      " c0: 0.9465648854961832 c1: 0.19642857142857142 bacc: 0.5714967284623773\n",
      "User S05 f1: 0.663961333434759 acc: 0.7048192771084337\n",
      " c0: 0.9487179487179487 c1: 0.1836734693877551 bacc: 0.5661957090528519\n",
      "User S06 f1: 0.6243021346469622 acc: 0.7028571428571428\n",
      " c0: 0.944 c1: 0.1 bacc: 0.522\n",
      "User S07 f1: 0.6626807254006375 acc: 0.6961325966850829\n",
      " c0: 0.888 c1: 0.2857142857142857 bacc: 0.5868571428571429\n",
      "User S08 f1: 0.5938002714544676 acc: 0.6810810810810811\n",
      " c0: 0.9523809523809523 c1: 0.1694915254237288 bacc: 0.5609362389023406\n",
      "User S09 f1: 0.7020380739081747 acc: 0.7446808510638298\n",
      " c0: 0.9323308270676691 c1: 0.38181818181818183 bacc: 0.6570745044429255\n",
      "User S10 f1: 0.6131032885838934 acc: 0.7074468085106383\n",
      " c0: 0.9224806201550387 c1: 0.3898305084745763 bacc: 0.6561555643148075\n",
      "User S11 f1: 0.6685267236424982 acc: 0.7125748502994012\n",
      " c0: 0.9159663865546218 c1: 0.16666666666666666 bacc: 0.5413165266106442\n",
      "User S12 f1: 0.787870711378174 acc: 0.8068181818181818\n",
      " c0: 0.9754098360655737 c1: 0.5185185185185185 bacc: 0.7469641772920461\n",
      "User S13 f1: 0.62383323134019 acc: 0.6815642458100558\n",
      " c0: 0.9349593495934959 c1: 0.32142857142857145 bacc: 0.6281939605110337\n",
      "User S14 f1: 0.6374286505230404 acc: 0.7071823204419889\n",
      " c0: 0.944 c1: 0.07142857142857142 bacc: 0.5077142857142857\n",
      "User S15 f1: 0.6004753322405972 acc: 0.6775956284153005\n",
      " c0: 0.9212598425196851 c1: 0.07142857142857142 bacc: 0.49634420697412823\n",
      "User S16 f1: 0.6309055551155813 acc: 0.6994535519125683\n",
      " c0: 0.9609375 c1: 0.10909090909090909 bacc: 0.5350142045454546\n",
      "User S17 f1: 0.7261301778447896 acc: 0.7650602409638554\n",
      " c0: 0.9655172413793104 c1: 0.16 bacc: 0.5627586206896552\n",
      "User S19 f1: 0.6020245319081816 acc: 0.6793478260869565\n",
      " c0: 0.9682539682539683 c1: 0.1724137931034483 bacc: 0.5703338806787083\n",
      "User S20 f1: 0.7957824076087745 acc: 0.8166666666666667\n",
      " c0: 0.968 c1: 0.34545454545454546 bacc: 0.6567272727272727\n",
      "average 0.6650136634600993\n",
      "\n",
      "0.5840485964008015\n",
      "0.2238609810235602\n",
      "0.944236211778043\n"
     ]
    }
   ],
   "source": [
    "from utilities.userfold_framework import *\n",
    "from Models.AR_EEG_models import *\n",
    "import Models.model_func as Model_Func\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlhttp://localhost:8888/notebooks/EEG-ModelTraining-LSTM_EEGNet-Weight-EEG.ipynb#ib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List\n",
    "from torcheeg.models import EEGNet\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "DEVICE= torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "learning_rate = 0.00005\n",
    "batch_size = 64\n",
    "n_epochs = 300\n",
    "transpose_channels=True\n",
    "participants_dictionary=[]\n",
    "participants_grads_dictionary={}\n",
    "b_acc_list=[]\n",
    "c0_acc_list=[]\n",
    "c1_acc_list=[]\n",
    "\n",
    "for r in range(5):\n",
    "    participants_dictionary=[]\n",
    "    for i in range(len(participants)):\n",
    "\n",
    "        train_dataloader, val_dataloader, classes, input_dim, class_ratio= user_fold_load(i,\n",
    "                                                                                          raw_user_fold,\n",
    "                                                                                          participants,\n",
    "                                                                                          batch_size=batch_size,\n",
    "                                                                                          transpose_channels=transpose_channels)\n",
    "\n",
    "        eegnet= EEGNet(\n",
    "            chunk_size=input_dim[1],\n",
    "            num_electrodes=input_dim[0],\n",
    "            num_classes=classes,\n",
    "            kernel_1= 32,\n",
    "            kernel_2=32,\n",
    "            F1=8,\n",
    "            F2=16,\n",
    "            dropout=0.5\n",
    "        ).to(DEVICE)\n",
    "\n",
    "\n",
    "    #     optimizer= torch.optim.RMSprop(classifier.parameters(), lr=learning_rate)\n",
    "\n",
    "        criterion= torch.nn.CrossEntropyLoss(weight=torch.tensor(class_ratio, dtype=torch.float).to(DEVICE))\n",
    "    #     criterion = nn.NLLLoss(weight=torch.tensor(class_ratio, dtype=torch.float).to(DEVICE))\n",
    "\n",
    "        saved_dir= f\"./EEG/saved_models/Userfold/run{r}\"\n",
    "        classifier = LSTM_EEGNet_Wrapper(DEVICE, eegnet, input_dim).to(DEVICE)\n",
    "        model = EEGNet_IE_EEG_Wrapper(DEVICE, classifier, input_dim[0]).to(DEVICE)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "        scheduler= torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2)\n",
    "\n",
    "\n",
    "#         train_func= eeg_train\n",
    "#         model.training_procedure(iteration=n_epochs,\n",
    "#                                         train_dataloader=train_dataloader,\n",
    "#                                          val_dataloader=val_dataloader,\n",
    "#                                          print_cycle=2,\n",
    "#                                          path=f\"./dictionary/intermdiate_dicts\",\n",
    "#                                          loss_func=criterion,\n",
    "#                                          optimiser=optimizer, #scheduler=scheduler,\n",
    "#                                          train_func=train_func\n",
    "#                                         )\n",
    "#         if model.epoch == n_epochs+1:\n",
    "#             EPOCH= n_epochs\n",
    "#         else:\n",
    "#             EPOCH= model.epoch\n",
    "\n",
    "#         torch.save(model.state_dict(), \n",
    "#                os.path.join(\n",
    "#                    saved_dir, f\"Userfold-{participants[i]}-LSTM_EEGNet-Weight_EEG-e{EPOCH}.pt\"\n",
    "#                )\n",
    "#         )\n",
    "\n",
    "#         pickle.dump( model.return_IE_weights(), \n",
    "#                     open(f\"{saved_dir}/Userfold-{participants[i]}-LSTM_EEGNet-Weight_EEG-w-e{EPOCH}.pkl\", \"wb\") \n",
    "#                    )    \n",
    "\n",
    "    # OR\n",
    "        model.load_state_dict(\n",
    "        torch.load(\n",
    "            open(\n",
    "                os.path.join(\n",
    "                    saved_dir, f\"Userfold-{participants[i]}-LSTM_EEGNet-Weight_EEG-e{n_epochs}.pt\"\n",
    "                ), \"rb\"\n",
    "            )\n",
    "                  )\n",
    "        )\n",
    "\n",
    "        prediction, dictionary= model.prediction_procedure(val_dataloader, dict_flag=True)\n",
    "\n",
    "        ys= np.concatenate([y.detach().cpu().numpy() for x, y in val_dataloader])\n",
    "\n",
    "        c0_acc, c1_acc, b_acc= calculate_accuracy(ys, prediction)\n",
    "        print(\"c0_acc\", c0_acc, \", c1_acc\", c1_acc, \", b_acc\", b_acc)\n",
    "        b_acc_list.append(b_acc)\n",
    "        c0_acc_list.append(c0_acc)\n",
    "        c1_acc_list.append(c1_acc)\n",
    "        participants_dictionary.append(dictionary)\n",
    "#     pickle.dump(participants_dictionary, open(f\"{saved_dir}/participant_dictionary-LSTM_EEGNet-Weight_EEG.pkl\",\"wb\"))\n",
    "\n",
    "\n",
    "tmp=[]\n",
    "for i, dictionary in enumerate(participants_dictionary):\n",
    "    print(f\"User {participants[i]} f1: {dictionary['weighted avg']['f1-score']} acc: {dictionary['accuracy']}\")\n",
    "    print(f\" c0: {c0_acc_list[i]} c1: {c1_acc_list[i]} bacc: {b_acc_list[i]}\")\n",
    "    tmp.append(dictionary['weighted avg']['f1-score'])\n",
    "\n",
    "print(f\"average {np.mean(tmp)}\")\n",
    "print()\n",
    "print(np.array(b_acc_list).mean())\n",
    "print(np.array(c1_acc_list).mean())\n",
    "print(np.array(c0_acc_list).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9de653",
   "metadata": {},
   "outputs": [],
   "source": [
    "userfold_results_summary(participants_dictionary, participants)\n",
    "userfold_classwise_results_summary(participants_dictionary, participants)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9ee100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# channel_names=[i for i in range(input_dim[0])]\n",
    "channel_names=[\"AFz\",\"F3\",\"F1\",\"Fz\",\"F2\",\"F4\",\"FC5\",\"FC3\",\"FC1\",\"FCz\",\"FC2\",\n",
    "               \"FC4\",\"FC6\",\"C5\",\"C3\",\"C1\",\"Cz\",\"C2\",\"C4\",\"C6\",\"CP5\",\"CP3\",\n",
    "               \"CP1\",\"CPz\",\"CP2\",\"CP4\",\"CP6\",\"P3\",\"P1\",\"Pz\",\"P2\",\"P4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3762af43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "participants_w_list=[]\n",
    "\n",
    "for i in range(len(participants)):\n",
    "\n",
    "    w= pickle.load(\n",
    "        open(f\"{saved_dir}/Userfold-{participants[i]}-LSTM_EEGNet-Weight_EEG-w-e{EPOCH}.pkl\", \"rb\") \n",
    "                    )  \n",
    "    participants_w_list.append(w)\n",
    "    \n",
    "avg_w= np.array(participants_w_list).mean(axis=0)\n",
    "# scaler= MinMaxScaler()\n",
    "# scaled_avg_w= scaler.fit_transform(avg_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd52006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import mne\n",
    "info= mne.create_info(channel_names, sfreq=500, ch_types=32*[\"eeg\"])\n",
    "info.set_montage(\"standard_1020\")\n",
    "\n",
    "fig= plt.figure()\n",
    "ax= plt.axes((0,0,1.5,1.5))\n",
    "\n",
    "scaler= MinMaxScaler()\n",
    "scaled_avg_w= scaler.fit_transform(avg_w.sum(1).reshape(-1,1))\n",
    "# df= pd.DataFrame(scaled_avg_w.reshape(-1))\n",
    "\n",
    "im, _= mne.viz.plot_topomap(\n",
    "    scaled_avg_w.reshape(-1),\n",
    "    info,\n",
    "    ch_type= \"eeg\",\n",
    "    sensors=True,\n",
    "    names=channel_names,\n",
    "    cmap=\"Blues\",\n",
    "    axes=ax,\n",
    "    show=False,\n",
    "    extrapolate=\"local\"\n",
    "#     sphere=\"eeglab\"\n",
    ")\n",
    "fig.add_axes(ax)\n",
    "cbar_ax= fig.add_axes([1.3,0.2, 0.1,1])\n",
    "clb= fig.colorbar(im, cax=cbar_ax)\n",
    "clb.set_label(\"Importance Estimate\", rotation=270,labelpad=20)\n",
    "\n",
    "for tt in plt.findobj(fig, matplotlib.text.Text):\n",
    "    if tt.get_text() in channel_names:\n",
    "        tt.set_fontsize(14)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
